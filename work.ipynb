{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"X:\\Programs\\Anaconda3\\lib\\site-packages\\nltk\\decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\nX:\\Programs\\Anaconda3\\lib\\site-packages\\nltk\\lm\\counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n  from collections import Sequence, defaultdict\nX:\\Programs\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n  warnings.warn(msg, category=DeprecationWarning)\n"}],"source":"from pymongo import MongoClient\nfrom gensim.models.wrappers.ldamallet import malletmodel2ldamodel\nfrom gensim.test.utils import common_texts\nfrom gensim.corpora.dictionary import Dictionary\nfrom gensim.models.wrappers import LdaMallet\nfrom gensim.models import LdaModel\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import preprocess_documents\nfrom sklearn.pipeline import Pipeline\nimport pyLDAvis.gensim\nimport time\nimport os\nimport random\n\nfrom preprocessor import *\n"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Conectando ao MongoDB"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"\nclient = MongoClient('localhost', 27017)\ndb = client[\"discursoDB\"]\ndiscursos = db[\"discursos\"]"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Discursos preprocessados, demorou 00:29:52:01\n"}],"source":"start_time = time.time()\n\n# all_discursos = discursos.find()\n\n# discursos_list = random.sample(list(all_discursos), 5000)\n\n# discursos_list = discursos.find(\n#     {\"$and\": [\n#         {\"SiglaPartidoParlamentarNaData\": {\"$eq\": \"PT\"}},\n#         {\"Conteudo\": {\n#             \"$ne\": \"\"\n#         }}\n#     ]})\n\n# discursos_list = random.sample(list(discursos_list), 1)\n\ndiscursos_list = discursos.find({\"Conteudo\": {\n            \"$ne\": \"\"\n        }})\n\ntext = []\n\nfor disc in discursos_list:\n    text.append(disc[\"Conteudo\"])\n\npipe = Pipeline([\n    ('cleaning', Cleaner()),\n    ('stopwords', StopWords(lang='portuguese', tokenize=True)),\n    ('stemming', Stemmer(lang='portuguese', fit_reuse=True))])\npipe.fit(text)\nres = pipe.transform(text)\n\n# preproc = Preprocessor(max_word_lenght=2)\n# preproc.fit(text)\n# text = preproc.transform(text)\n\nelapsed_time = time.time() - start_time\nprint(time.strftime(\"Discursos preprocessados, demorou %H:%M:%S:%m\",\n                    time.gmtime(elapsed_time)))\n"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":"with open(\"discursos_all.txt\", 'w+') as f:\n    f.write(str(res))"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"abdi nasciment blocopdtrj lid pronunc seguint discurs president sras srs senador proposit assum hoj tribun inform presidenc dest cas coleg senador realiz ontem reunia final comissa julgament premi cruz sous honr particip lad senador esperidia amin deput paul gouv poet gerard mell moura professor iaponan soar trabalh apresent numer consider excelent funca pouc temp dispunh candidat oit hav sid elimin imediat raza hav autor infring regul artig estabelec carat individual cad obra referent necess identificaca pseudonim relat datalimit entreg trabalh monograf restant enta distribu decisa comissa dois relator poet gerard mell moura responsavel examin trabalh categor geral professor iaponan soar fic categor estud ambos apresent ontem relatori unanim aprov comissa diss result escolh vencedor assim categor estud fic primeir lug monograf intitul cruz sous sol negr autor carl albert shimot martins jair sant ampar cruz sous biograf autor unic trabalh merec menca honros ness categor luis claudi ribeir pinh autor cruz sous simbol transcultural primeir coloc categor geral menco honros atribu eneddy till magal sant mour mari guidarin carl henriqu alme segund regul concurs primeir coloc recebera mil cad tera trabalh public lad daquel obtiv menca honros expens sen cerimon premiaca dev ter lug agost proxim dat ser defin finaliz gost registr bel pec liter relatori apresent inspir poet gerard mell moura propr pequen ilumin ensai sobr vid obra cruz sous cuj leitur certez contribu enriquec conhec tod brasileir dot sensibil amor arte pec transcrit integr pagin ana dest cas president comunicaca desej faz obrig\n"}],"source":"f = open(\"discursos_all.txt\",\"r\")\ndiscursos_file = f.read()\nf.close()\n\ny = eval(discursos_file)\n\nprint(y[0])"},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":"''"},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":"y[8]"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":"'aloizi mercad blocopt revisa orador president seman pass sub tribun fiz pronunc long sobr cris sen cerc tres hor mei receb vint apart senador pratic tod legend entant nao consegu pesso fiz entend men profund sentiment realment estav busc constru enfrent resolv cris sen tamb dialog president sarney duas circunstanc inclusiv pratic tod banc dialog president luiz inaci lul silv objet tamb nest cas interpretaco divers muit dir absolut improcedent diant quer express posica banc atrav not escrit formaliz bastant objet not oficial banc sen senador part trabalh comunic lideranc moment algum discussa sobr cris sen exig integr abdic posico individu tampouc fez president republ luiz inaci lul silv durant encontr palaci alvor seman pass portant banc sent respeit president lul autonom parlament sen reafirm banc senador long tod discussa sobr cris sen mantev posica suger gest grandez garant credibil investigaco senador jos sarney licenc temporari sen pud aprofund investigaco constru propost soluca problem encontr admit entant fez maior part cas licenc decisa ser tom senador cris sen estrutural grav envolv aspect etic polit relev sempr defend reform profund corrig distorco administraca sen tant apresent nom dest propost mudanc candidatur senador tia vian president diant diss assev disposica promov aco polit reform estrutural urgent sen ampla providenc import anunc criaca comissa suprapartid debat sociedad civil especial reform sen mei inclusiv lei respons administr financeir parlament part projet banc anex coorden senador tia vian comissa nao concorrent mes diretor pois dev ter funca complement elabor propost melhor governanc sen parlament assim control social democrat gesta funcion permanent colegi lid democratiz deciso vid legisl administr instituica reduca progress ate tet despes pessoal extinca estrutur interleg institut legisl brasileir unileg substituica estrutur racional alem enxug servic atend medic sen exclus atend emergenc redistribu atribuico secret outr secret mes diretor exempl exist cam tud propost anex apresent banc prazolimit exercici carg direca ate quatr anos coincident mes diretor extinca pagament adicional salarial participaca funcionari conselh comisso espec ambit congress nacional final banc defend necess aprofund investigaco amplial tod possiv responsav tomandos dev providenc leg ocorr tribunal cont unia ministeri public polic federal divers med esta send tom mes diretor sen efeit exig temp produz mudanc necess result apresent comissa sindicanc abertur process demissa bem servic public unificaca contrachequ abertur portal transparenc nov diretriz hor extras restrico credit passagens alem outr med reduca despes pessoal brasil julh banc sen obrig'"},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":"res[0]\n# \" \".join(pipe.predict([res[0]])[0])\n"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"\nstart_time = time.time()\n# Create a corpus from a list of texts\ndata = [a.split() for a in res]\n\ndictionary = Dictionary(data)\n\ncorpus = [dictionary.doc2bow(t) for t in data]\n"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"\nmallet_path = 'X:\\\\Programs\\\\mallet\\\\mallet-2.0.8\\\\bin\\\\mallet.bat'"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n    \"\"\"\n    Compute c_v coherence for various number of topics\n\n    Parameters:\n    ----------\n    dictionary : Gensim dictionary\n    corpus : Gensim corpus\n    texts : List of input texts\n    limit : Max num of topics\n\n    Returns:\n    -------\n    model_list : List of LDA topic models\n    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n    \"\"\"\n    coherence_values = []\n    model_list = []\n    for num_topics in range(start, limit, step):\n        model = LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=dictionary)\n        model_list.append(model)\n        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n        coherence_values.append(coherencemodel.get_coherence())\n\n    return model_list, coherence_values"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'CoherenceModel' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-13-91d325eae6fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_coherence_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m<ipython-input-12-7a689d987e15>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[1;34m(dictionary, corpus, texts, limit, start, step)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLdaMallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mmodel_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mcoherencemodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c_v'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mcoherence_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoherencemodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'CoherenceModel' is not defined"]}],"source":"model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=res, start=2, limit=40, step=6)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"\n# os.environ['MALLET_HOME'] = 'X:\\\\Programs\\\\mallet\\\\mallet-2.0.8\\\\'\nmallet_path = 'X:\\\\Programs\\\\mallet\\\\mallet-2.0.8\\\\bin\\\\mallet.bat'\n\n# Train the model on the corpus.\nlda = LdaMallet(mallet_path, corpus, id2word=dictionary, num_topics=20)\n# lda = LdaModel(corpus, id2word=dictionary, num_topics=10, alpha='auto', eval_every=5, chunksize=10, passes=10, decay=0.9)\n\nelapsed_time = time.time() - start_time\nprint(time.strftime(\"Lda model criado, demorou %H:%M:%S:%m\", time.gmtime(elapsed_time)))\n"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"for index, topic in lda.show_topics(formatted=False, num_words=10):\n    print('Topic: {} \\nWords: {}'.format(\n        index, [pipe.predict([w[0]])[0][0] for w in topic]))\n        # index, [pipe.predict([w[0]])[0][0] for w in topic]))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}